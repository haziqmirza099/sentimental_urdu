import streamlit as st
import spacy
import speech_recognition as sr
from pydub import AudioSegment
from sklearn.feature_extraction.text import CountVectorizer
from joblib import load
from urduhack.preprocessing import (
    normalize_whitespace,
    remove_punctuation,
    remove_accents,
    replace_urls,
    replace_emails,
    replace_numbers,
    replace_currency_symbols,
)
from urduhack.models.lemmatizer import lemmatizer

class UrduTextPreprocessor:
    def __init__(self):
        self.nlp = spacy.blank('ur')
        self.URDU_PUNCTUATIONS = ['\u200F', '\u200f', 'Û”', 'Ù«', 'Ùª', 'ØŸ', 'ØŒ', ')', '(', '{', '}', 'â€¦', 'Û”Û”Û”', '/', '?', '.', '#']
        self.stop_words = frozenset("""
            Ø¢ Ø¢Ø¦ÛŒ Ø¢Ø¦ÛŒÚº Ø¢Ø¦Û’ Ø¢ØªØ§ Ø¢ØªÛŒ Ø¢ØªÛ’ Ø¢Ø¯Ø§Ø¨ Ø¢Ø¯Ú¾ Ø¢Ø¯Ú¾Ø§ Ø¢Ø¯Ú¾ÛŒ Ø¢Ø¯Ú¾Û’ Ø¢Ø³ Ø¢Ù…Ø¯ÛŒØ¯ Ø¢Ù†Ø§ Ø¢Ù†Ø³Û Ø¢Ù†ÛŒ Ø¢Ù†Û’ Ø¢Ù¾ Ø¢Ú¯Û’ Ø¢Û Ø¢ÛØ§ Ø¢ÛŒØ§ Ø§Ø¨ Ø§Ø¨Ú¾ÛŒ Ø§Ø¨Û’
            Ø§ØªÙˆØ§Ø± Ø§Ø±Ø¨ Ø§Ø±Ø¨ÙˆÛŒÚº Ø§Ø±Û’ Ø§Ø³ Ø§Ø³Ú©Ø§ Ø§Ø³Ú©ÛŒ Ø§Ø³Ú©Û’ Ø§Ø³ÛŒ Ø§Ø³Û’ Ø§Ù Ø§ÙÙˆÛ Ø§Ù„Ø§ÙˆÙ„ Ø§Ù„Ø¨ØªÛ Ø§Ù„Ø«Ø§Ù†ÛŒ Ø§Ù„Ø­Ø±Ø§Ù… Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ù Ø§Ù„Ù…Ú©Ø±Ù… Ø§Ù† Ø§Ù†Ø¯Ø± Ø§Ù†Ú©Ø§ Ø§Ù†Ú©ÛŒ Ø§Ù†Ú©Û’
            Ø§Ù†ÛÙˆÚº Ø§Ù†ÛÛŒ Ø§Ù†ÛÛŒÚº Ø§ÙˆØ¦Û’ Ø§ÙˆØ± Ø§ÙˆÙ¾Ø± Ø§ÙˆÛÙˆ Ø§Ù¾ Ø§Ù¾Ù†Ø§ Ø§Ù¾Ù†ÙˆÚº Ø§Ù¾Ù†ÛŒ Ø§Ù¾Ù†Û’ Ø§Ù¾Ù†Û’Ø¢Ù¾ Ø§Ú©Ø¨Ø± Ø§Ú©Ø«Ø± Ø§Ú¯Ø± Ø§Ú¯Ø±Ú†Û Ø§Ú¯Ø³Øª Ø§ÛØ§ÛØ§ Ø§ÛŒØ³Ø§ Ø§ÛŒØ³ÛŒ Ø§ÛŒØ³Û’
            Ø§ÛŒÚ© Ø¨Ø§Ø¦ÛŒÚº Ø¨Ø§Ø± Ø¨Ø§Ø±Û’ Ø¨Ø§Ù„Ú©Ù„ Ø¨Ø§ÙˆØ¬ÙˆØ¯ Ø¨Ø§ÛØ± Ø¨Ø¬ Ø¨Ø¬Û’ Ø¨Ø®ÛŒØ± Ø¨Ø±Ø³Ø§Øª Ø¨Ø´Ø±Ø·ÛŒÚ©Û Ø¨Ø¹Ø¶ Ø¨ØºÛŒØ± Ø¨Ù„Ú©Û Ø¨Ù† Ø¨Ù†Ø§ Ø¨Ù†Ø§Ø¤ Ø¨Ù†Ø¯ Ø¨Ú‘ÛŒ Ø¨Ú¾Ø± Ø¨Ú¾Ø±ÛŒÚº Ø¨Ú¾ÛŒ
            Ø¨ÛØ§Ø± Ø¨ÛØª Ø¨ÛØªØ± Ø¨ÛŒÚ¯Ù… ØªØ§Ú©Û ØªØ§ÛÙ… ØªØ¨ ØªØ¬Ú¾ ØªØ¬Ú¾ÛŒ ØªØ¬Ú¾Û’ ØªØ±Ø§ ØªØ±ÛŒ ØªÙ„Ú© ØªÙ… ØªÙ…Ø§Ù… ØªÙ…ÛØ§Ø±Ø§ ØªÙ…ÛØ§Ø±ÙˆÚº ØªÙ…ÛØ§Ø±ÛŒ ØªÙ…ÛØ§Ø±Û’ ØªÙ…ÛÛŒÚº ØªÙˆ ØªÚ© ØªÚ¾Ø§ ØªÚ¾ÛŒ
            ØªÚ¾ÛŒÚº ØªÚ¾Û’ ØªÛØ§Ø¦ÛŒ ØªÛŒØ±Ø§ ØªÛŒØ±ÛŒ ØªÛŒØ±Û’ ØªÛŒÙ† Ø¬Ø§ Ø¬Ø§Ø¤ Ø¬Ø§Ø¦ÛŒÚº Ø¬Ø§Ø¦Û’ Ø¬Ø§ØªØ§ Ø¬Ø§ØªÛŒ Ø¬Ø§ØªÛ’ Ø¬Ø§Ù†ÛŒ Ø¬Ø§Ù†Û’ Ø¬Ø¨ Ø¬Ø¨Ú©Û Ø¬Ø¯Ú¾Ø± Ø¬Ø³ Ø¬Ø³Û’ Ø¬Ù† Ø¬Ù†Ø§Ø¨ Ø¬Ù†ÛÙˆÚº
            Ø¬Ù†ÛÛŒÚº Ø¬Ùˆ Ø¬ÛØ§Úº Ø¬ÛŒ Ø¬ÛŒØ³Ø§ Ø¬ÛŒØ³ÙˆÚº Ø¬ÛŒØ³ÛŒ Ø¬ÛŒØ³Û’ Ø¬ÛŒÙ¹Ú¾ Ø­Ø§Ù„Ø§Ù†Ú©Û Ø­Ø§Ù„Ø§Úº Ø­ØµÛ Ø­Ø¶Ø±Øª Ø®Ø§Ø·Ø± Ø®Ø§Ù„ÛŒ Ø®Ø¯Ø§ Ø®Ø²Ø§Úº Ø®ÙˆØ§Û Ø®ÙˆØ¨ Ø®ÙˆØ¯ Ø¯Ø§Ø¦ÛŒÚº Ø¯Ø±Ù…ÛŒØ§Ù† Ø¯Ø±ÛŒÚº
            Ø¯Ùˆ Ø¯ÙˆØ±Ø§Ù† Ø¯ÙˆØ³Ø±Ø§ Ø¯ÙˆØ³Ø±ÙˆÚº Ø¯ÙˆØ³Ø±ÛŒ Ø¯ÙˆØ´Ù†Ø¨Û Ø¯ÙˆÚº Ø¯Ú©Ú¾Ø§Ø¦ÛŒÚº Ø¯Ú¯Ù†Ø§ Ø¯ÛŒ Ø¯ÛŒØ¦Û’ Ø¯ÛŒØ§ Ø¯ÛŒØªØ§ Ø¯ÛŒØªÛŒ Ø¯ÛŒØªÛ’ Ø¯ÛŒØ± Ø¯ÛŒÙ†Ø§ Ø¯ÛŒÙ†ÛŒ Ø¯ÛŒÙ†Û’ Ø¯ÛŒÚ©Ú¾Ùˆ Ø¯ÛŒÚº Ø¯ÛŒÛ’ Ø¯Û’ Ø°Ø±ÛŒØ¹Û’
            Ø±Ú©Ú¾Ø§ Ø±Ú©Ú¾ØªØ§ Ø±Ú©Ú¾ØªÛŒ Ø±Ú©Ú¾ØªÛ’ Ø±Ú©Ú¾Ù†Ø§ Ø±Ú©Ú¾Ù†ÛŒ Ø±Ú©Ú¾Ù†Û’ Ø±Ú©Ú¾Ùˆ Ø±Ú©Ú¾ÛŒ Ø±Ú©Ú¾Û’ Ø±Û Ø±ÛØ§ Ø±ÛØªØ§ Ø±ÛØªÛŒ Ø±ÛØªÛ’ Ø±ÛÙ†Ø§ Ø±ÛÙ†ÛŒ Ø±ÛÙ†Û’ Ø±ÛÙˆ Ø±ÛÛŒ Ø±ÛÛŒÚº Ø±ÛÛ’
            Ø³Ø§ØªÚ¾ Ø³Ø§Ù…Ù†Û’ Ø³Ø§Ú‘Ú¾Û’ Ø³Ø¨ Ø³Ø¨Ú¾ÛŒ Ø³Ø±Ø§Ø³Ø± Ø³Ù„Ø§Ù… Ø³Ù…ÛŒØª Ø³ÙˆØ§ Ø³ÙˆØ§Ø¦Û’ Ø³Ú©Ø§ Ø³Ú©ØªØ§ Ø³Ú©ØªÛ’ Ø³Û Ø³ÛÛŒ Ø³ÛŒ Ø³Û’ Ø´Ø§Ù… Ø´Ø§ÛŒØ¯ Ø´Ú©Ø±ÛŒÛ ØµØ§Ø­Ø¨ ØµØ§Ø­Ø¨Û ØµØ±Ù
            Ø¶Ø±ÙˆØ± Ø·Ø±Ø­ Ø·Ø±Ù Ø·ÙˆØ± Ø¹Ù„Ø§ÙˆÛ Ø¹ÛŒÙ† ÙØ±ÙˆØ±ÛŒ ÙÙ‚Ø· ÙÙ„Ø§Úº ÙÛŒ Ù‚Ø¨Ù„ Ù‚Ø·Ø§ Ù„Ø§Ø¦ÛŒ Ù„Ø§Ø¦Û’ Ù„Ø§ØªØ§ Ù„Ø§ØªÛŒ Ù„Ø§ØªÛ’ Ù„Ø§Ù†Ø§ Ù„Ø§Ù†ÛŒ Ù„Ø§ÛŒØ§ Ù„Ùˆ Ù„ÙˆØ¬ÛŒ Ù„ÙˆÚ¯ÙˆÚº Ù„Ú¯
            Ù„Ú¯Ø§ Ù„Ú¯ØªØ§ Ù„Ú¯ØªÛŒ Ù„Ú¯ÛŒ Ù„Ú¯ÛŒÚº Ù„Ú¯Û’ Ù„ÛØ°Ø§ Ù„ÛŒ Ù„ÛŒØ§ Ù„ÛŒØªØ§ Ù„ÛŒØªÛŒ Ù„ÛŒØªÛ’ Ù„ÛŒÚ©Ù† Ù„ÛŒÚº Ù„ÛŒÛ’ Ù„Û’ Ù…Ø§Ø³ÙˆØ§ Ù…Øª Ù…Ø¬Ú¾ Ù…Ø¬Ú¾ÛŒ Ù…Ø¬Ú¾Û’ Ù…Ø­ØªØ±Ù… Ù…Ø­ØªØ±Ù…ÛŒ
            Ù…Ø­Ø¶ Ù…Ø±Ø§ Ù…Ø±Ø­Ø¨Ø§ Ù…Ø±ÛŒ Ù…Ø±Û’ Ù…Ø²ÛŒØ¯ Ù…Ø³ Ù…Ø³Ø² Ù…Ø³Ù¹Ø± Ù…Ø·Ø§Ø¨Ù‚ Ù…Ø·Ù„Ù‚ Ù…Ù„ Ù…Ù†Ù¹ Ù…Ù†Ù¹ÙˆÚº Ù…Ú©Ø±Ù…ÛŒ Ù…Ú¯Ø± Ù…Ú¯Ú¾Ø± Ù…ÛØ±Ø¨Ø§Ù†ÛŒ Ù…ÛŒØ±Ø§ Ù…ÛŒØ±ÙˆÚº Ù…ÛŒØ±ÛŒ Ù…ÛŒØ±Û’ Ù…ÛŒÚº
            Ù†Ø§ Ù†Ø²Ø¯ÛŒÚ© Ù†Ù…Ø§ Ù†Ùˆ Ù†ÙˆÙ…Ø¨Ø± Ù†Û Ù†ÛÛŒÚº Ù†ÛŒØ² Ù†ÛŒÚ†Û’ Ù†Û’ Ùˆ ÙˆØ§Ø± ÙˆØ§Ø³Ø·Û’ ÙˆØ§Ù‚Ø¹ÛŒ ÙˆØ§Ù„Ø§ ÙˆØ§Ù„ÙˆÚº ÙˆØ§Ù„ÛŒ ÙˆØ§Ù„Û’ ÙˆØ§Û ÙˆØ¬Û ÙˆØ±Ù†Û ÙˆØ¹Ù„ÛŒÚ©Ù… ÙˆØºÛŒØ±Û
            ÙˆÙ„Û’ ÙˆÚ¯Ø±Ù†Û ÙˆÛ ÙˆÛØ§Úº ÙˆÛÛŒ ÙˆÛÛŒÚº ÙˆÛŒØ³Ø§ ÙˆÛŒØ³Û’ ÙˆÛŒÚº Ù¾Ø§Ø³ Ù¾Ø§ÛŒØ§ Ù¾Ø± Ù¾Ø³ Ù¾Ù„ÛŒØ² Ù¾ÙˆÙ† Ù¾ÙˆÙ†Ø§ Ù¾ÙˆÙ†ÛŒ Ù¾ÙˆÙ†Û’ Ù¾Ú¾Ø§Ú¯Ù† Ù¾Ú¾Ø± Ù¾Û Ù¾ÛØ± Ù¾ÛÙ„Ø§ Ù¾ÛÙ„ÛŒ
            Ù¾ÛÙ„Û’ Ù¾ÛŒØ± Ù¾ÛŒÚ†Ú¾Û’ Ú†Ø§ÛØ¦Û’ Ú†Ø§ÛØªÛ’ Ú†Ø§ÛÛŒØ¦Û’ Ú†Ø§ÛÛ’ Ú†Ù„Ø§ Ú†Ù„Ùˆ Ú†Ù„ÛŒÚº Ú†Ù„Û’ Ú†Ù†Ø§Ú†Û Ú†Ù†Ø¯ Ú†ÙˆÙ†Ú©Û Ú†ÙˆÚ¯Ù†ÛŒ Ú†Ú©ÛŒ Ú†Ú©ÛŒÚº Ú†Ú©Û’ Ú†ÛØ§Ø±Ø´Ù†Ø¨Û Ú†ÛŒØª ÚˆØ§Ù„Ù†ÛŒ
            ÚˆØ§Ù„Ù†Û’ ÚˆØ§Ù„Û’ Ú©Ø¦Û’ Ú©Ø§ Ú©Ø§ØªÚ© Ú©Ø§Ø´ Ú©Ø¨ Ú©Ø¨Ú¾ÛŒ Ú©Ø¯Ú¾Ø± Ú©Ø± Ú©Ø±ØªØ§ Ú©Ø±ØªÛŒ Ú©Ø±ØªÛ’ Ú©Ø±Ù… Ú©Ø±Ù†Ø§ Ú©Ø±Ù†Û’ Ú©Ø±Ùˆ Ú©Ø±ÛŒÚº Ú©Ø±Û’ Ú©Ø³ Ú©Ø³ÛŒ Ú©Ø³Û’ Ú©Ù„ Ú©Ù…
            Ú©Ù† Ú©Ù†ÛÛŒÚº Ú©Ùˆ Ú©ÙˆØ¦ÛŒ Ú©ÙˆÙ† Ú©ÙˆÙ†Ø³Ø§ Ú©ÙˆÙ†Ø³Û’ Ú©Ú†Ú¾ Ú©Û Ú©ÛØ§ Ú©ÛØ§Úº Ú©ÛÛ Ú©ÛÛŒ Ú©ÛÛŒÚº Ú©ÛÛ’ Ú©ÛŒ Ú©ÛŒØ§ Ú©ÛŒØ³Ø§ Ú©ÛŒØ³Û’ Ú©ÛŒÙˆÙ†Ú©Ø± Ú©ÛŒÙˆÙ†Ú©Û Ú©ÛŒÙˆÚº Ú©ÛŒÛ’ Ú©Û’
            Ú¯Ø¦ÛŒ Ú¯Ø¦Û’ Ú¯Ø§ Ú¯Ø±Ù…Ø§ Ú¯Ø±Ù…ÛŒ Ú¯Ù†Ø§ Ú¯Ùˆ Ú¯ÙˆÛŒØ§ Ú¯Ú¾Ù†Ù¹Ø§ Ú¯Ú¾Ù†Ù¹ÙˆÚº Ú¯Ú¾Ù†Ù¹Û’ Ú¯ÛŒ Ú¯ÛŒØ§ ÛØ§Ø¦ÛŒÚº ÛØ§Ø¦Û’ ÛØ§Ú‘ ÛØ§Úº ÛØ± ÛØ±Ú†Ù†Ø¯ ÛØ±Ú¯Ø² ÛØ²Ø§Ø± ÛÙØªÛ ÛÙ…
            ÛÙ…Ø§Ø±Ø§ ÛÙ…Ø§Ø±ÛŒ ÛÙ…Ø§Ø±Û’ ÛÙ…ÛŒ ÛÙ…ÛŒÚº ÛÙˆ ÛÙˆØ¦ÛŒ ÛÙˆØ¦ÛŒÚº ÛÙˆØ¦Û’ ÛÙˆØ§ ÛÙˆØ¨ÛÙˆ ÛÙˆØªØ§ ÛÙˆØªÛŒ ÛÙˆØªÛŒÚº ÛÙˆØªÛ’ ÛÙˆÙ†Ø§ ÛÙˆÙ†Ú¯Û’ ÛÙˆÙ†ÛŒ ÛÙˆÙ†Û’ ÛÙˆÚº ÛÛŒ
            ÛÛŒÙ„Ùˆ ÛÛŒÚº ÛÛ’ ÛŒØ§ ÛŒØ§Øª ÛŒØ¹Ù†ÛŒ ÛŒÚ© ÛŒÛ ÛŒÛØ§Úº ÛŒÛÛŒ ÛŒÛÛŒÚº
        """.split())
        self.abusive_words = set([
            "Ú¯Ø¯Ú¾Ø§","Ø§Ø±Û’ Ø¨ÛÙ†Ú†ÙˆØ¯"," Ø¨ÛÙ† Ú†ÙˆØ¯ÙˆÚº","Ú¯ * * * Ù¾Ú¾Ù¹ Ø¬Ø§Ø¦Û’ ","Ø¨ * * * * * *","Ø¨ÛÙ†Ú†ÙˆØ¯", "ÛŒØ§Ø± Ø¨ÛÙ† Ù„ÙˆÚˆÙˆ","Ù†Ù†Ú¯ÛŒ Ú©Û’ Ø¨Ú†Û’ ","Ú†Ú¾ÙˆÚ‘Ùˆ Ù…Ø§Ø¯Ø± Ú†ÙˆØ¯Ùˆ","ÙØ§Ø¦Ø± Ú¯Ø§Ù†ÚˆÙˆ", "Ú¯Ø¯Ú¾Û’","Ø§Ø¨Û’ Ù…Ø§Úº Ú©Û’ Ù„ * * *", "Ø­Ø±Ø§Ù… Ø²Ø§Ø¯Û","", "Ø­Ø±Ø§Ù… Ø²Ø§Ø¯ÛŒ", "Ø­Ø±Ø§Ù…ÛŒ", "Ú©Ù…ÛŒÙ†Û", "Ú©Ù…ÛŒÙ†Û’", "Ú©Ù…ÛŒÙ†ÛŒ", "Ú©ØªÛŒ", "Ú©ØªØ§", 
            "Ú©ØªÛ’", "Ù¾Ú¾Ø¯ÛŒ", "Ù„Ù†Úˆ","Ø¨ÛÙ† Ú©ÛŒ Ú† * *", "Ù…Ø§Úº Ú†ÙˆØ¯", "Ø§ÙÙ„Ù‘Ùˆ", "Ø¨Ø³Ø±Úˆ", "Ø¨Ú¾ÙˆØ³Ú‘ÛŒ", "Ú©Ù†Ø¬Ø±", "Ú†ÙˆØªÛŒØ§", "Ù…Ø§Úº Ú†ÙˆØ¯", "Ù…Ø§Úº Ú†ÙˆØ¯", "Ù…Ø§Ú†ÙˆØ¯","Ø§Ù„Ùˆ" 
            "Ù…Ø§Úº Ú†ÙˆØ¯", "Ù…ÛŒØ§Ø¯Ø§", "Ù…ÛŒØ§Ø¯Ø§", "Ø§ÙÙ„Ù‘Ùˆ", "Ø§ÙÙ„Ù‘Ùˆ", "Ø§ÙÙ„Ù‘Ùˆ", "Ø§ÙÙ„Ù‘Ùˆ Ú©ÛŒ Ù¾ØªÛŒ", "Ø§ÙÙ„Ù‘Ùˆ", "Ø§ÙÙ„Ù‘Ùˆ Ú©Ø§ Ù¾Ù¹Ú¾Ø§","Ø± * * * Ú©Û’ Ø¨Ú†Û’","Ø± * * * ",
            "Ø§ÙÙ„Ù‘Ùˆ Ú©Ø§ Ù¾Ù¹Ú¾Ø§", "Ø§ÙÙ„Ù‘Ùˆ Ú©Ø§ Ù¾ØªØ§", "Ø¨Ø³Ø±Úˆ Ú†ÙˆØ¯ÛŒ", "Ø¨Ú¾ÙˆØ³Ú‘ÛŒ", "Ø¨ÙˆØ³Ú‘Û’ Ú©Û’", "Ø¨ÙˆØ³Ú‘ÛŒ Ú©Û’", "Ø¨ÙˆØ³Ú‘Û’ Ú©Û’", "Ø¨ÙˆØ³Ú‘ÛŒ Ú©Û’","Ø¨ÛÙ† Ú†ÙˆØ¯ÙˆÚº" 
            "Ø¨ÙˆØ³Ú‘ÛŒ Ú©Û’","Ú¯Ø§Ù†ÚˆÙˆ","Ú©ØªÛŒÛ’","Ú†ÙˆØªÛŒÛ’","Ø¨Ú¾Ú‘ÙˆÛ’","Ø± * * * Ú©Û’ Ø¨Ú†Û’","Ù…Ø§Úº Ú©ÛŒ Ú† * * ÛÙ†Ø¯ÛŒ Ú©Û’ Ø¨Ú†Û’","Ù¾ÛŒÙ† Ø¯Ø§ Ù¾Ú¾Ø¯Ø§ Ù¾Ú¾Ø¯Ø§ Ù¾Ú¾Ø¯Ø§","Ø¨ÛÙ† Ø¯Ø§ Ù¾Ú¾Ø¯Ø§","ØªÛŒØ±ÛŒ Ù¾ÛŒÙ† Ø¯Ø§ Ù¾Ú¾Ø¯Ø§ Ù¾ÛŒÙ† Ú†ÙˆØ¯Ø§","ØªÛŒØ±ÛŒ Ø§ÛŒÙ† Ø¯Ø§ Ù¾Ú¾Ø¯Ø§"," Ø¯Ø§ Ù¾Ú¾Ø¯Ø§","Ú†Ù†Ø§Ù„ Ú©ÛŒ Ø§ÙˆÙ„Ø§Ø¯ Ú©ÛŒ Ú† * * Ø§Ø³ Ú©ÛŒ Ù…Ø§Úº Ú©Û’ Ù„ * * * Ù„Ú¯Ø§","Ú†Ù†Ø§Ù„ Ú©ÛŒ Ø§ÙˆÙ„Ø§Ø¯ Ú©ÛŒØ§","Ù…Ø§Úº Ú†ÙˆØ¯ÙˆÚº Ø¨Ú¾Ú‘Ú©ÛŒ Ú©ÛŒ","Ú†Ø¯Ø§","Ú†ÙˆØªÛŒØ§","Ø§Ù¾Ù†ÛŒ Ù…Ø§Úº Ú†Ø¯Ø§ Ø±ÛÛ’ ÛÙˆ","Ú¯ * * * Ù…ÛŒÚº ÚˆØ§Ù„Ùˆ Ù¾ÙˆÙ„ÛŒØ³","Ú¯ * * * Ù…Ø±Ø§ Ø±ÛÛ’ ÛÛŒÚº Ø¨ÛÙ† Ú©Û’ Ù„Ø¤Ú‘Û’","Ø¨ * * * * * * Ø³Ù…Ø¬Ú¾ Ø³Û’ Ø¨Ø§ÛØ± ÛÛ’ "," Ø¨ * * * * * * ØªÙˆ", "Ø¨ÙˆØ³Ú‘Û’ Ú©Û’","Ø± * * * Ú©Û’ Ø¨Ú†Û’","Ø§Ø¨Û’ Ø¨ÛÙ† Ú©Û’ Ù„Ø¤Ú‘Û’"," Ø¨ÛÙ† Ú©Û’ Ù„ * * * Ù…Ø§Úº Ú†Ø¯Ø§ Ø±ÛØ§ ÛÙˆÚº","Ù…Ø§Ø¯Ø±Ú†ÙˆØ¯"," Ú¯ * * * Ù…Ø±Ø§ Ø±ÛÛ’ ÛÙˆ", "Ø­Ø±Ø§Ù…", "Ø­Ø±Ø§Ù…ÛŒ","Ø¨Ú¾Ú‘ÙˆÛ’ Ù…Ø§Ø¯Ø±Ú†ÙˆØ¯"," Ø¨ÛÙ†Ú†ÙˆØ¯","Ø¨ÛÙ† Ú©ÛŒ Ù„ÙˆÚ‘ÛŒ ","Ø§Ø±Û’ Ø¨ÛÙ† Ú©Û’ Ù„Ø¤Ú‘Û’","Ú¯ * * * Ù…Ø±Ø§Ù†Û’","Ù…Ø§Úº Ú©Ùˆ Ú†ÙˆØ¯ÙˆÚº","Ø¨ÛÙ†Ú†ÙˆØ¯ Ø± * * * Ú©Ø§ Ø¨Ú†Û"
        ])

    def remove_punctuations(self, text):
        return ''.join([char if char not in self.URDU_PUNCTUATIONS else ' ' for char in text])

    def remove_stopwords(self, text):
        return " ".join(word for word in text.split() if word not in self.stop_words)

    def lemmatize(self, text):
        lemme_str = ""
        temp = lemmatizer.lemma_lookup(text)
        for t in temp:
            lemme_str += t[0] + " "
        return lemme_str.strip()

    def normalize_text(self, text):
        text = remove_accents(text)
        text = normalize_whitespace(text)
        text = replace_currency_symbols(text)
        text = replace_emails(text)
        text = replace_numbers(text)
        text = replace_urls(text)
        return text

    def preprocess(self, text):
        text = self.remove_punctuations(text)
        text = " ".join([token.text for token in self.nlp(text)])
        text = self.normalize_text(text)
        text = self.remove_stopwords(text)
        text = self.lemmatize(text)
        return text

    def detect_abusive_words(self, text):
        for word in text.split():
            if word in self.abusive_words:
                return True
        return False

    def convert_to_wav(self, input_file, output_file):
        if input_file.endswith(".wav"):
            return input_file
        else:
            audio = AudioSegment.from_file(input_file)
            audio.export(output_file, format="wav")
            return output_file

    def recognize_and_preprocess_audio(self, audio_file):
        wav_file = self.convert_to_wav(audio_file, "output.wav")
        recognizer = sr.Recognizer()
        with sr.AudioFile(wav_file) as source:
            audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language="ur-PK")
            preprocessed_text = self.preprocess(text)
            print("Preprocessed Transcription:", preprocessed_text)
            return preprocessed_text
        except sr.UnknownValueError:
            print("Google Speech Recognition could not understand the audio.")
            return None
        except sr.RequestError as e:
            print("Could not request results from Google Speech Recognition service; {0}".format(e))
            return None


def callback(recognizer, audio):
    try:
        text = recognizer.recognize_google(audio, language="ur-PK")
        preprocessed_text = preprocessor.preprocess(text)
        print("Preprocessed Transcription:", preprocessed_text)

        if preprocessor.detect_abusive_words(preprocessed_text):
            print("Abusive SentenceğŸš«")
        else:
            X_sentence = cv_loaded.transform([preprocessed_text])
            prediction = model.predict(X_sentence)

            if prediction[0] == 1:
                print("Negative SentenceğŸ˜ ")
            elif prediction[0] == 0:
                print("Positive SentenceğŸ˜Š")
            else:
                print("Neutral SentenceğŸ˜")

    except sr.UnknownValueError:
        print("Google Speech Recognition could not understand the audio.")
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")


cv_loaded = load('countvectorizer_updateddr4.joblib')
model = load('sentiNB_updateddr4.joblib')

preprocessor = UrduTextPreprocessor()

def main():
    option = st.input("Select mode: (1) File-based Audio Processing (2) Real-time Audio Processing: ")

    if option == '1':
        audio_file_path = st.input("Enter the path to the audio file: ")
        preprocessed_text = preprocessor.recognize_and_preprocess_audio(audio_file_path)
        print("Preprocessed Text:", preprocessed_text)

        if preprocessed_text:
            if preprocessor.detect_abusive_words(preprocessed_text):
                print("Abusive SentenceğŸš«")
            else:
                X_sentence = cv_loaded.transform([preprocessed_text])
                prediction = model.predict(X_sentence)

                if prediction[0] == 1:
                    print("Negative SentenceğŸ˜ ")
                elif prediction[0] == 0:
                    print("Positive SentenceğŸ˜Š")
                else:
                    print("Neutral SentenceğŸ˜")

    elif option == '2':
        recognizer = st.sr.Recognizer()
        mic = st.sr.Microphone()

        stop_listening = recognizer.listen_in_background(mic, callback)

        print("Listening for incoming audio... Press Ctrl+C to stop.")

        import time
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            stop_listening(wait_for_stop=False)
            print("Stopped listening.")

if __name__ == "__main__":
    main()
